{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T12:22:20.489126Z",
     "start_time": "2019-04-27T12:22:19.147972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WPU-Net\\segmentation\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os, copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import torchvision.transforms as tr\n",
    "from model import UNet, WPU_Net\n",
    "from tools import posprecess, stitch, proprecess_img, tailor, get_expansion\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from weight_map_loss import caculate_weight_map\n",
    "\n",
    "import pdb, sys\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "transform = tr.Compose([\n",
    "    tr.ToTensor(),\n",
    "    tr.Normalize(mean = [ 0.9336267],    # RGB\n",
    "                std = [ 0.1365774])\n",
    "])\n",
    "\n",
    "cwd = os.getcwd()\n",
    "output_test_dir = os.path.join(cwd, \"../datasets\", \"segmentation\", \"net_test\", \"test\")\n",
    "output_test_crop_dir = os.path.join(cwd, \"../datasets\", \"segmentation\", \"net_test\", \"test_overlap_crop\")\n",
    "output_train_dir = os.path.join(cwd, \"../datasets\", \"segmentation\", \"net_train\", \"train\")\n",
    "output_train_crop_dir = os.path.join(cwd, \"../datasets\", \"segmentation\", \"net_train\", \"train_crop\")\n",
    "output_val_dir = os.path.join(cwd, \"../datasets\", \"segmentation\", \"net_train\", \"val\")\n",
    "output_val_crop_dir = os.path.join(cwd, \"../datasets\", \"segmentation\", \"net_train\", \"val_crop\")\n",
    "\n",
    "name = 'WPU_Net_model'\n",
    "\n",
    "model_path = \"./parameter/\"+name+\"/best_model_state.pth\"\n",
    "result_save_dir = \"./result/\"+name+\"/\"\n",
    "result_total_save_dir = \"./result_total/\"+name+\"/\"\n",
    "\n",
    "if not os.path.exists(result_save_dir):\n",
    "    os.makedirs(result_save_dir)\n",
    "    \n",
    "if not os.path.exists(result_total_save_dir):\n",
    "    os.makedirs(result_total_save_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T12:22:28.187724Z",
     "start_time": "2019-04-27T12:22:23.388528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_layer  True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): WPU_Net(\n",
       "    (down1): Conv3x3(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (down2): Conv3x3(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(65, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (down3): Conv3x3(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(129, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (down4): Conv3x3(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(257, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (bottom): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv3x3(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up1): UpConcat(\n",
       "      (deconv): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (upconv1): Conv3x3(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (up2): UpConcat(\n",
       "      (deconv): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (upconv2): Conv3x3(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (up3): UpConcat(\n",
       "      (deconv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (upconv3): Conv3x3(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (up4): UpConcat(\n",
       "      (deconv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (upconv4): Conv3x3(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (final): Sequential(\n",
       "      (0): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (pool): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WPU_Net(num_channels=2, multi_layer=True) \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "    \n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "end ... 0.13544202223420143\n",
      "5\n",
      "149\n",
      "150\n",
      "3   3\n",
      "150   1\n",
      "151\n",
      "3   3\n",
      "151   2\n",
      "152\n",
      "3   3\n",
      "152   3\n",
      "153\n",
      "3   3\n",
      "153   4\n",
      "end...\n",
      "Wall time: 9.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import glob\n",
    "\n",
    "DATA_FOLDER = output_test_crop_dir\n",
    "images = sorted(os.listdir(os.path.join(DATA_FOLDER, \"images\")))\n",
    "print(len(images))\n",
    "\n",
    "start_time = time.time()\n",
    "count = 0\n",
    "\n",
    "min_file = 149   # 1  117  149\n",
    "max_file = 153   # 116  148  296\n",
    "\n",
    "for item in images:\n",
    "    if item.endswith(\".png\"):\n",
    "        filename = item.split(\".\")[0]\n",
    "        pic_num = item.split(\"_\")[0]\n",
    "        if int(pic_num) > min_file and int(pic_num) <= max_file:\n",
    "            count += 1\n",
    "            \n",
    "            name = filename\n",
    "\n",
    "            test_image = os.path.join(DATA_FOLDER, \"images/\"+name+\".png\")\n",
    "            img = proprecess_img(test_image)\n",
    "            \n",
    "            # WPU-Net\n",
    "            last_name = str(int(pic_num) - 1).zfill(3) + '_' + filename.split('_')[1] + '_' + filename.split('_')[2]\n",
    "            last_mask = cv2.imread(os.path.join(DATA_FOLDER, \"labels/\"+last_name+\".png\"), 0)\n",
    "\n",
    "            last_tensor = torch.Tensor(np.array(last_mask)).unsqueeze(0).unsqueeze(0)\n",
    "            \n",
    "#             # last mask\n",
    "            last_tensor[last_tensor == 255] = -6\n",
    "            last_tensor[last_tensor == 0] = 1\n",
    "        \n",
    "            output = model(inputs = img, last = last_tensor)\n",
    "\n",
    "            result_npy = posprecess(output, close=True)\n",
    "            \n",
    "            cv2.imwrite(os.path.join(result_save_dir, filename+\".png\"), result_npy)\n",
    "            \n",
    "end_time = time.time()\n",
    "average_time = (end_time - start_time)/count\n",
    "print(\"end ...\", average_time)\n",
    "\n",
    "DATA_FOLDER = output_test_dir\n",
    "imgList = sorted(os.listdir(os.path.join(DATA_FOLDER, \"images\")))\n",
    "print(len(imgList))\n",
    "\n",
    "n = 0\n",
    "for img in imgList:\n",
    "    if img.endswith(\".png\"):\n",
    "        name = img.split(\".\")[0]\n",
    "        print(name)\n",
    "        if int(name) > min_file and int(name) <= max_file:\n",
    "            stitch(256, 256, name, result_save_dir, result_total_save_dir+name+\".png\", 32)\n",
    "            n += 1\n",
    "            print(name, \" \", n)\n",
    "print(\"end...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate  \n",
    "\n",
    "from evaluation import eval_RI_VI, eval_F_mapKaggle\n",
    "\n",
    "RI_save_dir = \"./evaluations/big_RI_VI/\"\n",
    "Map_save_dir = \"./evaluations/big_F_mAP/\"\n",
    "\n",
    "if not os.path.exists(RI_save_dir):\n",
    "    os.makedirs(RI_save_dir)\n",
    "    \n",
    "if not os.path.exists(Map_save_dir):\n",
    "    os.makedirs(Map_save_dir)\n",
    "    \n",
    "print(\"WPU_Net_model \" + \"#####\"*20)\n",
    "eval_RI_VI(\"./result_total/WPU_Net_model/\", RI_save_dir+\"WPU_Net_model.txt\")\n",
    "eval_F_mapKaggle(\"./result_total/WPU_Net_model/\", Map_save_dir+\"WPU_Net_model.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16.0,
    "lenType": 16.0,
    "lenVar": 40.0
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
